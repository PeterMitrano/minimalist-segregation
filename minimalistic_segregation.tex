\documentclass[letterpaper, 10 pt, conference]{ieeeconf}
\IEEEoverridecommandlockouts
\overrideIEEEmargins
\usepackage{cite}
\usepackage{xcolor}
\usepackage{mathtools}
\usepackage{footnote}
\usepackage{cancel}
\usepackage{xfrac}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage[hidelinks]{hyperref}
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage{float}
\usepackage{pgf,tikz,pgfplots}
\usepackage{units}
\usepackage{textcomp}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

%\pgfplotsset{compat=1.15}
\usepackage{mathrsfs}
\usetikzlibrary{arrows,arrows.meta,automata,calc,intersections,positioning}
\definecolor{sexdts}{rgb}{0.1803921568627451,0.49019607843137253,0.19607843137254902}
\definecolor{dtsfsf}{rgb}{0.8274509803921568,0.1843137254901961,0.1843137254901961}
\definecolor{wrwrwr}{rgb}{0.3803921568627451,0.3803921568627451,0.3803921568627451}
\definecolor{rvwvcq}{rgb}{0.08235294117647059,0.396078431372549,0.7529411764705882}
\definecolor{cqcqcq}{rgb}{0.7529411764705882,0.7529411764705882,0.7529411764705882}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\newcommand{\myparagraph}[1]{\textbf{#1.}}
\renewcommand{\vec}[1]{\ensuremath{\mathbf{#1}}}

\begin{document}

\title{\LARGE \bf
A Minimalistic Approach to Segregation\\
in Robot Swarms}

\author{
  Peter~Mitrano$^{1}$,
  Jordan~Burklund$^{1}$,
  Michael~Giancola$^{1}$,
  Carlo~Pinciroli$^{1}$%
  \thanks{$^{1}$ Robotics Engineering, Worcester Polytechnic Institute, MA, USA. Email: {\sf cpinciroli@wpi.edu}}%
}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

\begin{abstract}
  We present a decentralized algorithm to achieve segregation into an arbitrary
  number of groups with swarms of autonomous robots. The distinguishing feature
  of our approach is in the minimalistic assumptions on which it is
  based. Specifically, we assume that (i) Each robot is equipped with a ternary
  sensor capable of detecting the presence of a single nearby robot, and, if
  that robot is present, whether or not it belongs to the same group as the
  sensing robot; (ii) The robots move according to a differential drive model;
  and (iii) The structure of the control system is purely reactive, and it maps
  directly the sensor readings to the wheel speeds with a simple `if' statement.
  We present a thorough analysis of the parameter space
  that enables this behavior to emerge, along with idealized conditions for
  convergence and a study of non-ideal aspects in the robot design.
  % TODO change this if the proofs work out
\end{abstract}

\section{Introduction}

Group formation is one of the most fundamental mechanisms a robot swarm must
exhibit~\cite{Brambilla2013}. Group formation can occur in several forms to
satisfy different requirements. Segregation is a particular type of group
formation in which the focus is on creating local aggregates of robots that
share a common property. Segregation can be seen as a precursor to object
sorting, task allocation, or self-assembly. For example, swarms may need to
split into arbitrary groups to diffuse and search different areas, or segregate
by skill or capability in order to form useful heterogeneous teams.

Segregation is an example of the broader class of spatially organizing
behaviors, whose purpose is to impose a structure in the environment (e.g.,
object clustering~\cite{gauci_clustering_2014}, collective
construction~\cite{Bolger2010}) or in the distribution of the robots (e.g.,
aggregation~\cite{shlyakhov_survey_2017}, pattern
formation~\cite{Pinciroli:DARS2016}, self-assembly~\cite{gross2008self}).

A recent line of research in spatially organizing behaviors focuses on the
\emph{minimal} assumptions a swarm of robots must fulfill in order to perform the
task. Johnson and Brown~\cite{johnson_evolving_2016} and Brown \emph{et
al.}~\cite{brown_discovery_2018} characterized the set of possible behaviors
that can be obtained using primordial control strategies based on a simple
`if/then/else' structure, binary sensors, and differential-drive robots. Gauci
\emph{et al.} provided the specific conditions for the emergence of
aggregation~\cite{gauci_evolving_2014} and object
clustering~\cite{gauci_clustering_2014}, while St.-Onge \emph{et
al.}~\cite{StOnge:IROS2018} studied the emergence of circular
formations. While more efficient control strategies have been proposed to
achieve these behaviors, studying the minimal assumptions required for their emergence is
an important step towards principled `swarm engineering' practices. In addition,
these minimal behaviors might offer last-resort solutions in case of sensor
failures in remote environments such as in planetary exploration missions.

This paper furthers this line of inquiry by studying the minimal assumptions for
$N$-class segregation to emerge from local, decentralized interactions among
robots. The term `$N$-class' refers to the creation of $N$ spatially distinct
groups. We show that, for segregation to emerge, it is sufficient to equip an
`if/then/else', differential drive robot with a \emph{ternary} sensor. This
sensor detects the presence of a robot in range. When a robot is detected, the
sensor can distinguish whether it is a \emph{kin}, i.e., it belongs to the same
group as the sensing robot, or a \emph{non-kin}, i.e., it belongs to a different
group. When multiple robots are in range, the sensor returns information on the
closest one of them.

The main contributions of this paper are \emph{(i)} A study of the parameter
space that enables the emergence of $N$-class segregation; \emph{(ii)} A study
of why convergence is guaranteed for the best parameter choice found; and
\emph{(iii)} An analysis of the robustness of the algorithm to non-idealities in
the robot design.

\section{Related Work}
Segregation is a common behavior in nature, and it can be observed across
scales. For example, cell segregation is a basic building block of embryogeneis
in tissue generation processes~\cite{batlle_molecular_2012,Steinberg1963}; while
social insects, such as ants, organize their brood into ring-like
structures~\cite{Franks1992}.

In robotics, segregation is a problem that has not received considerable
attention. The main methods that have been proposed so far are based on some
variation of the artificial potential approach~\cite{Spears2004}, which assumes
that the robots can detect each other and estimate relative distance vectors.

Gro\ss~\emph{et al.}~\cite{gross_segregation_2009} proposed an
algorithm inspired by the Brazil Nut effect, in which the robots form regular
layers simulating gravity by sharing a common direction. This study was later
extended to work on e-pucks robots~\cite{Chen2012}. To simulate gravity, this
approach requires the robots to share a common target vector, which can be
obtained through centralized controllers or a distributed consensus algorithm.

Kumar \emph{et al.}~\cite{kumar_segregation_2010} introduced the concept of
``differential potential'', whereby two robots experience a different artificial
potential depending on their being part of the same class or not. The
convergence of this approach is guaranteed for two classes, but when more
classes are employed local minima prevent segregation from emerging.

Santos \emph{et al.}~\cite{santos_segregation_2014} took inspiration
from~\cite{kumar_segregation_2010} to devise an approach based on the
Differential Adhesion Hypothesis, which states that kin cells tend to adhere
stronger than non-kin cells. However, one limitation is the assumption
that the robots have global knowledge about the positions of other robots.

To the best of our knowledge, this paper is the first to propose a segregation
algorithm that is not based on global information nor on communication and
sensing of multiple neighbors.

\section{Methodology}

\subsection{Problem Formulation}

\newcommand{\vL}{\ensuremath{v_{\text{left}}}}
\newcommand{\vR}{\ensuremath{v_{\text{right}}}}
\newcommand{\vaL}{\ensuremath{V_{\text{left}}}}
\newcommand{\vaR}{\ensuremath{V_{\text{right}}}}
\newcommand{\VM}{\ensuremath{V_{\text{max}}}}
\myparagraph{Motion model}
We consider a set of robots executing the same controller in a two-dimensional,
obstacle-free environment. The robots are equipped with two wheels for which
$[\vL,\vR]$ denote their \emph{normalized} linear speeds. By `normalized' we
mean that the speed values are in the range $[-1, 1]$. Using normalized speeds
allows us to reason in a general way over the specific speeds attainable by any
robot. To transform from normalized speeds $[\vL,\vR]$ into actual speeds
$[\vaL,\vaR]$, we introduce a parameter $\VM$ that denotes the maximum linear
speed possible with a specific robot and define
\begin{align}
  \vaL &= \VM \vL\\
  \vaR &= \VM \vR.
\end{align}
The robots' motion assuming constant wheel velocities is modeled by the well-known differential-drive
equations, shown in Equation \eqref{eq:motion}.

\newcommand{\vPN}[2]{\ensuremath{v_{\text{#1}}}^{S=#2}}
\newcommand{\robot}[2]{%
  \filldraw[draw=#2,fill=#2!20] (#1) circle(5mm);
  \draw[draw=#2,->,-Stealth,rotate around={0:(#1)}] (#1) -- +(5mm,0);
  \fill[fill=gray!20] ($(#1)+(5mm,0)$) -- +( 45:1cm) -- +(-45:1cm) -- cycle;%
  \fill[fill=#2] ($(#1)+(5mm,0)$) circle (1mm);%
  }
  \begin{figure}[t]
    \centering
    \begin{tikzpicture}
      \coordinate (s0) at (0  cm,0cm);
      \coordinate (s1) at (1.5cm,0cm);
      \coordinate (s2) at (3  cm,0cm);
      \robot{s0}{red};
      \robot{s1}{red};
      \robot{s2}{blue};
      \node[below=of s0]{\texttt{S=1}};
      \node[below=of s1]{\texttt{S=2}};
      \node[below=of s2]{\texttt{S=0}};
    \end{tikzpicture}
    \caption{A diagram of the ternary sensor in which classes are depicted
    as colors. The left red robot detects a kin robot, so its sensor
    returns 1. The middle red robot detects a blue robot, so its sensor
    returns 2. The right robot detects no robot, so its sensor returns
    0.}
    \label{fig:sensor}
  \end{figure}

  \begin{algorithm}[t]
    \begin{algorithmic}
      \If {$S=0$} \State set wheel speeds to $\vPN{left}{0}$, $\vPN{right}{0}$
      \ElsIf {$S=1$} \State set wheel speeds to $\vPN{left}{1}$, $\vPN{right}{1}$
      \Else \State set wheel speeds to $\vPN{left}{2}$, $\vPN{right}{2}$
      \EndIf
    \end{algorithmic}
    \caption{The segregation control algorithm.}
    \label{alg:controller}
  \end{algorithm}

  \myparagraph{Sensor model}
  The robots are also equipped with a ternary sensor that is able to detect the
  presence of nearby robots and their ``kinness''. Two robots are \emph{kin} if
  they belong to the same class (denoted by color in our experiments); they are
  \emph{non-kin} otherwise. The sensor is assumed to have infinite range (we
  consider non-infinite range in Sec.~\ref{section:beam_range}). As depicted in
  Fig.~\ref{fig:sensor}, the sensor returns a reading $S=0$ when no robot is
  detected, $S=1$ when a kin robot is detected, and $S=2$ when a non-kin robot is
  detected. We allow for any number of classes, but the sensor need not
  distinguish between different non-kin classes---it only detects whether a nearby
  robot belongs to the same class or not.

  \myparagraph{Control logic}
  The control logic followed by the robots is formalized in
  Alg.~\ref{alg:controller}. It is a simple `if/then/else' structure, which maps
  the sensor readings $S$ directly into normalized wheel speeds $[\,\vL\;\vR\,]$. The
  latter are the parameters whose value we intend to study, and they can be
  encoded as a six-dimensional vector
  $$
  [\,
  \vPN{left}{0}\;
  \vPN{right}{0}\;
  \vPN{left}{1}\;
  \vPN{right}{1}\;
  \vPN{left}{2}\;
  \vPN{right}{2}\;
  \,].
  $$

  \myparagraph{Objective}
  The objective of our study is to find the values of the speed parameters for
  which the robots group into clusters, such that all the robots of the same class
  are packed into one cluster with no non-kin robots.

  \subsection{Simulation Environment and Robots}

  \myparagraph{Simulation platform} We utilized the ARGoS multi-robot
  simulator~\cite{pinciroli_argos:_2012} to search for controller parameters and
  evaluate them. ARGoS offers accurate models for several differential-drive
  robots, such as the foot-bot~\cite{Bonani2010}, the Khepera
  IV\footnote{https://www.k-team.com/khepera-iv}, and the
  Kilobot~\cite{Rubenstein2012}.

  \myparagraph{Simulated Robot platform}
  For the simulated experiments we opted to use the foot-bot, because of the
  possibility to utilize its range-and-bearing communication system as a base for
  the ternary sensor. The advantage of using the range-and-bearing system is that
  its model is simple and, as a consequence, a large number of simulations could
  be completed in a short time. The range-and-bearing system allows two robots to
  exchange messages when they are in direct line-of-sight; upon receiving a
  message, a robot can also estimate the relative position of the sender. This
  sensor, in principle, receives messages from all the nearby robots. To simulate
  the ternary sensor, our robot controller kept the message of the closest
  robot. The message payload was an integer that encoded the id of the group to
  which the sender belonged. The range-and-bearing sensor is simulated through ray
  casting. This allowed us to assume that the sensor reading is infinitely thin, a
  choice that simplifies the mathematical analysis presented in
  Sec.~\ref{sec:analysis}. However, in practical applications, the sensor can be
  expected to cast a cone-shaped sensory range with non-zero aperture angle. We
  explore the performance effect of various angles in
  Sec.~\ref{sec:aperture_angle}.

  \myparagraph{Real Robot platform}
  We used the Turtlebot 3 robots equipped with Raspberry Pi cameras.
  To implement the ternary sensor, we placed bightly color skirts on each robot
  and used OpenCV blob-detection to identify the color of the robot. Each robot
  knows it's own color, this way kin versus non-kin robots can be identified.
  We use a threshold on blob size and color values to distinguish whether there
  are any robots in our line of sight.

  \subsection{Grid Search}
  \label{sec:gridsearch}

  \myparagraph{Trial setup}
  In order to exhaustively search the space of possible controllers, we conducted
  a grid search of the 6-dimensional parameter space. Due to limited computational
  resources, we were only able to search with a resolution of $7$ values per
  parameter: $[-1, \sfrac{-2}{3}, \sfrac{-1}{3}, 0, \sfrac{1}{3}, \sfrac{2}{3}, 1]$.
  In total we evaluated $7^6=117,649$ parameter sets. For
  each parameter set, we tested 36 different initial configurations (8 with 1-class, 8 with 2-class, 20 with 4-class),
  with 100 simulated seconds for each trial. These initial configurations consisted of
  uniformly random placement, clusters, and lines of robots distributed throughout
  the environment. We chose to include some structured configurations (clusters
  and lines) because we discovered that they affected significantly the
  performance with respect to uniform random configurations. Hence, by explicitly
  evaluating diverse initial configurations, we could better estimate the best
  parameter values in the general case. Examples of these starting configurations
  can be seen in our supplementary videos~\footnote{\href{https://www.youtube.com/playlist?list=PL9HqYJ1IkIKVX9EsT5BY9LnBsBPTjc5bB}{https://goo.gl/z8UAuB}}.

  \myparagraph{Clusters}
  To define our cost function, we first establish the notion of a cluster.
  A cluster can be intuitively defined as an island of connected kin robots.
  Formally, a cluster is a set of kin robots which are \emph{connected}.
  Denoting with $r$ the radius of the body of a robot, and defining
  $\vec{p}_i(t) = [x_i(t)\;y_i(t)]$ as the $x$ and $y$ coordinates of the robot at time $t$, we consider any two kin robots to be
  connected if
  \begin{equation} \label{eq:connected}
    \lVert\vec{p}_i(t) - \vec{p}_j(t)\rVert \le 2r + \epsilon \qquad (i \ne j, \epsilon \in \mathbb{R}^+)
  \end{equation}
  In our experiments, we set $\epsilon = \SI{5}{\centi\meter}$.
  We find clusters by first constructing an adjacency matrix and then performing a depth-first search.
  Since we are interested in segregating the robots in $N$ classes,
  the final result of a trial is expected to be a set of $N$ distinct clusters composed of kin robots.

  \myparagraph{Cost function}
  To measure the difference between the ideal, perfectly segregated result and any
  configuration achieved by the robots over time, we first calculate, for every
  class $i$, the number of robots in the largest cluster $c_i(t)$ formed by robots of class $i$.  Since,
  in principle, different classes might involve different numbers of robots, in
  our cost function we employ the ratio
  $$
  \gamma_i(t) = -\frac{c_i(t)}{C_i}
  $$
  This ratio should be maximized, so the negative sign assigns larger clusters a lower, more negative, cost.
  Here $C_i$ is the number of robots that belongs to class $i$. At each time step, the cost is
  $$
  \gamma(t) = \frac{1}{N}\sum_{i=1}^N\gamma_i(t)
  $$
  Our complete cost function is then
  \begin{equation}
    \label{eq:cost_function}
    c_{\text{total}} =  \sum_{t=0}^{T-1} t\gamma(t)
  \end{equation}
  in which we denote the total trial time (100 seconds) with $T$. The effect of multiplying $\gamma_i(t)$ by $t$ is to highlight the
  emergence of clusters as the trial time proceeds: we cannot expect large
  clusters to be present at the beginning of a trial, but good parameter settings
  should grow (and maintain) clusters over time. In our experiments, we found that
  $c_{\text{total}}$ correctly assigns cost in most scenarios, thus fitting
  well our analysis purposes. However, this cost function considers a straight
  line of robots to be a cluster, and as such it might not be ideal for scenarios
  in which the clusters are required to be tight.

  \begin{figure}[t]
    \centering
    \includegraphics[width=0.32\linewidth]{./images/0_1_grid_img}
    \includegraphics[width=0.32\linewidth]{./images/2_3_grid_img}
    \includegraphics[width=0.32\linewidth]{./images/4_5_grid_img}
    \includegraphics[width=0.32\linewidth]{./images/0_3_grid_img}
    \includegraphics[width=0.32\linewidth]{./images/0_5_grid_img}
    \includegraphics[width=0.32\linewidth]{./images/1_4_grid_img}
    \includegraphics[width=0.32\linewidth]{./images/1_2_grid_img}
    \includegraphics[width=0.32\linewidth]{./images/3_4_grid_img}
    \includegraphics[width=0.32\linewidth]{./images/2_5_grid_img}
    \includegraphics[width=0.32\linewidth]{./images/0_4_grid_img}
    \includegraphics[width=0.32\linewidth]{./images/1_5_grid_img}
    \includegraphics[width=0.32\linewidth]{./images/0_2_grid_img}
    \includegraphics[width=0.32\linewidth]{./images/1_3_grid_img}
    \includegraphics[width=0.32\linewidth]{./images/2_4_grid_img}
    \includegraphics[width=0.32\linewidth]{./images/3_5_grid_img}
    \caption{Heatmaps that relate relevant pairs of wheel speeds. Darker is worse.}
    \label{fig:gridsearch}
  \end{figure}

  \section{The Emergent Behavior}
  \myparagraph{Visualizing grid search}
  The results of grid search are reported in Fig.~\ref{fig:gridsearch}. Because
  the search space is six-dimensional, we chose to visualize it by plotting every
  pair of parameters against each other. For example, we consider how the cost
  changes as $\vPN{left}{0}$ and $\vPN{right}{0}$ change. As an example of reading
  these plots, we can tell from the plot of $\vPN{left}{1}$ and $\vPN{right}{1}$
  that there were no good controllers where the left and right wheel speeds were
  equal and negative (dark squares in the upper left), and that the best
  controllers had unequal values close to 1 (lightest squares in the
  bottom left). These plots also convey the presence of sharp discontinuities
  where performance changes dramatically.

  \myparagraph{The emergent behavior}
  After running the grid search, the parameters with the lowest mean cost across all 36
  starting configurations
  \begin{equation}
    \label{eq:controller}
    [-1, \sfrac{1}{3}, \sfrac{1}{3}, 1, -1, 1].
    \tag{C}
  \end{equation}

  The resulting behavior is for a robot to turn sharply until it detects a kin,
  then turn less sharply while it sees the kin. This change in the radius of rotation
  moves the robot closer to its kin. When a non-kin is seen, the robot turns in place.
  In isolation, the emergent behavior between kin and non-kin is similar to the aggregation behavior found by Gauci \emph{et al.}~\cite{gauci_evolving_2014}
  in that the robots are always turning in the same direction (counter-clockwise for our parameters).
  To our surprise, we found that the best segregation behavior requires that non-kin also aggregate.
  This was not only true for the best parameters, but for all of the top-scoring parameters we observed.
  To better appreciate the dynamics of this behavior, we invite the interested reader to watch the videos at
  \href{https://www.youtube.com/playlist?list=PL9HqYJ1IkIKVX9EsT5BY9LnBsBPTjc5bB}{https://goo.gl/z8UAuB}.

  \section{Behavior Analysis}
  \label{sec:analysis}
  Using the parameter settings~\eqref{eq:controller}, we now break down
  and analyze the emerging behavior.
  While we are not able to formally explain the segregation behavior among an arbitrary number of robots,
  we can instead consider simplified scenarios with two robots. In this section, we provide
  prove that, for the robot parameters considered in our experiments, two kin robots in isolation are guaranteed to aggregate.
  Interestingly, we also show that two isolated non-kin robots are also guaranteed to aggregate.
  These two guarantees partially explains the emergent behavior observed in our experiments.

  \newcommand{\ICC}{\ensuremath{\text{ICC}}}

  In the proofs, we employ the well-known equations that govern the instantaneous
  radius of curvature $R$ and rotation speed $\omega$ of the path followed a
  differential-drive robot with $l$ denoting the interwheel distance~\cite{Dudek2010}:
  \begin{equation} \label{eq:motion}
    \begin{aligned}
      R &= \frac{l}{2}\frac{\vaR + \vaL}{\vaR - \vaL} = \frac{l}{2}\frac{\vR + \vL}{\vR - \vL}\\
      \omega &= \frac{\vaR - \vaL}{l} = \frac{\VM(\vR - \vL)}{l}.
    \end{aligned}
  \end{equation}

  \begin{table}[b]
    \centering
    \begin{tabular}{|c|c|c|c|} \hline
      & $S=0$ & $S=1$ & $S=2$ \\ \hline
      $v_l$ & $-1$ & $\sfrac{1}{3}$ & $-1$ \\ \hline
      $v_r$ & $\sfrac{1}{3}$ & $1$ & $1$ \\ \hline
      $R$ & $\sfrac{-l}{4}$ & $l$ & $0$ \\ \hline
      $\omega$ & $\frac{4V}{3l}$ & $\frac{4V}{3l}$ & $\sfrac{4V}{3l}$ \\ \hline
    \end{tabular}
    \label{tab:omega_and_r}
    \caption{turning Radii and rotational velocities for the best parameters.}
  \end{table}

  Table \ref{tab:omega_and_r} shows values of $R$ and $\omega$ for each sensor value, which we then use in our proofs.

  We simplify the geometry by assuming that the sensor is an infinitely thin beam, that both robots are synchronized such that they take sensor readings at the same time, and that both robots act for the same $\Delta t = 0.1$ time step. Lastly, we assume the robots a radius of $r=0.085$, interwheel distance $l=0.14$, and scaling velocity $\VM$.

  We consider all of the possible sensor values ($S=0$, $S=1$, $S=2$) for a robot $i$ and a second robot $j$ in separate cases. However, the cases ($S_i=1$, $S_j=0$) and ($S_i=0$, $S_j=1$) and the cases ($S_i=2$, $S_j=0$) and ($S_i=0$, $S_j=2$) are equivalent so we need only prove aggregation for one of each pair. Furthermore, for two isolated robots, the cases where one robot sees a kin and the other sees a non-kin ($S_i=1$, $S_j=2$) and ($S_i=1$, $S_j=2$) are impossible. This leaves just 5 cases, and in each case we prove that the robots aggregate.

  We use $x$, $y$, and $\alpha$, collectively called a configuration, to indicate the location of robot $j$ relative to robot $i$. Without loss of generality, we will always consider robot $i$ to be at the origin and facing the positive $x$-axis. Rather than showing that the center point of the robots $p_i$ and $p_j$ aggregate, we show that the points $c_i$ and $c_j$ aggregate. These are the points around which the robot rotates in the $S=0$ case. These points are at a distance $\frac{l}{4}$ from the center of the robot, and therefore when $c_i=c_j$ the points $p_i$ and $p_i$ are at most $\frac{l}{2}$ apart. On a real robot, the half of the inner wheel distance $l$ must be less than the robot radius $r$ (or the wheels would protrude from the robot). Hence aggregation of $c_i$ and $c_j$ is equivalent to the aggregation of $p_i$ and $p_j$.

  % is this paragraph necessary?
  As discussed above, there are 5 sensor cases to be considered for two robots. In the ``see nothing'' case ($S_i=0$, $S_j=0$), we will prove that the points $c_i$ and $c_j$ remain at constant distance. We then prove that in the other 4 cases the points aggregate. Finally, if $c_i$ and $c_j$ are guaranteed to exit the ``see nothing'' case into one of the other four cases where they aggregate, then they must eventually aggregate regardless of when and how often they may transition between the different sensor cases.

  \begin{theorem}[Nothing Detected]\label{thm:nothing}
    In the case ($S_i=0$, $S_j=0$), the robots will transition to another case if
    \begin{equation}\label{eq:nothing}
      ||p_j - p_i|| \lessapprox 0.88825\text{\SI{}{m}}
    \end{equation}
  \end{theorem}
  \begin{proof}
    In this case the robots rotate around the points $c_i$ and $c_j$, and therefore these points are stationary. To prove that $c_i$ and $c_j$ eventually aggregate we must prove that the robots exit this case. In other words, we prove that one robot will eventually see the other. For this, the distance between the robots must be bounded. If the robots are too far away, then the beam could ``skip'' over the other robot. Figure \ref{fig:nothing} shows the robots in the configuration where this maximum distance is attained. All figures are to scale. We used the Geometry package Geogebra \cite{geogebra5} to solve for the bound in this equation.

    \begin{figure}[t]
      \centering
      \includegraphics[height=4cm]{./images/thm1.png}
      \caption{Two robots at the maximum distance at which the robots will not skip over seeing each other. Robot $i$ moves from $p_i$ to $p'_i$, and likewise for robot $j$. Without loss of generality, we place $p_i$ at the origin initially facing the positive $x$-axis. Figure is to scale.}
      \label{fig:nothing}
    \end{figure}
  \end{proof}

  \begin{theorem}[Kin Robots \#1]\label{thm:kin_1}
    In the case ($S_i=1$, $S_j=1$), the robots aggregate.
  \end{theorem}
  \begin{proof}
    %In this case, we have $(S_i=1, S_j=1)$, and aggregation is defined as $||c'_j- c'_i|| < ||c_j- c_i||$, and we aim to show that this holds for any valid $(x, y, \alpha)$. First, we draw the perpendicular bisector of $c_i$ and $c'_i$, shown as the black solid line in Figure \ref{fig:kin_1}. All points on the right of this line are further from $c_i$ than $c'_i$. Since $c'_j$ is on the right on this line, we can upper bound $||c'_j-c'_i||$ with $||c'_j-c_i||$. The dashed green circle in Figure \ref{fig:kin_1} shows this radius $||c'_j-c_i||$. Next, we note that $||c'_j-c_i|| < ||c_j-c_i||$, which visually means that the point $c_j$ can never be on or inside the dashed green circle. These $x,y$ region of possible locations for $p_j$ is shown in yellow, and the angle $\alpha$ is within the interval $[\ang{120}, \ang{240}]$, as shown in Figure \ref{fig:min_max_alpha}. Given these constraints on $(x,y,\alpha)$, the point $c'_j$ can clearly never be inside the circle. Therefore by transitivity, we have that $||c'_j- c'_i|| < ||c_j- c_i||$.

    %\begin{figure}[t]
      %\centering
      %\includegraphics[height=4cm]{./images/kin_1.png}
      %\caption{Theorem \ref{thm:kin_1}: Two kin who both see each other. Robot $i$ centered at $p_i$ moves from $c_i$ to $c'_i$, likewise with robot $j$. Figure is to scale.}
      %\label{fig:kin_1}
    %\end{figure}

    %\begin{figure}[t]
      %\centering
      %\includegraphics[height=4cm]{./images/min_max_alpha.png}
      %% todo add yellow region
      %\caption{The minimum and maximum $\alpha$ values for Theorems \ref{thm:kin_1} and \ref{thm:non_kin_1} are \ang{120} and \ang{240}. This is achieved when robot $j$ and its beam are tangent to robot $i$.}
      %\label{fig:min_max_alpha}
    %\end{figure}
  \end{proof}

  \begin{theorem}[Non-Kin Robots \#1]\label{thm:non_kin_1}
    In the case ($S_i=2$, $S_j=2$), the robots aggregate.
  \end{theorem}
  \begin{proof}
  \end{proof}

  \begin{theorem}[Kin Robots \#2]\label{thm:kin_2}
    In the case ($S_i=1$, $S_j=0$), the robots aggregate.
  \end{theorem}
  \begin{proof}
    \begin{figure}[t]
      \centering
      \includegraphics[height=4cm]{./images/kin_2.png}
      \caption{Theorem \ref{thm:kin_2}: Robot $i$ sees kin robot $j$. $c_i$ moves to $c'_i$ and is closer to $c_j$.}
      \label{fig:kin_2}
    \end{figure}

    Robot $j$ is in state $S=0$, rotating around the point $c_j$. Therefore $c_j$ is stationary, so we require $||c_j- c'_i|| < ||c_j- c_i||$. We draw the perpendicular bisector between $c_i$ and $c'_i$ (thick black line, Figure \ref{fig:kin_2}) and note that $c_j$ is always on the left side of this line, and therefore $||c_j- c'_i|| < ||c_j- c_i||$ holds.
  \end{proof}

  \begin{theorem}[Non-Kin Robots \#2]\label{thm:non_kin_2}
    In the case ($S_i=2$, $S_j=0$), the robots aggregate.
  \end{theorem}
  \begin{proof}
    \begin{figure}[t]
      \centering
      \includegraphics[height=4cm]{./images/non_kin_2.png}
      \caption{Theorem \ref{thm:non_kin_2}: Robot $i$ sees non-kin robot $j$. $c_i$ moves to $c'_i$ and is closer to $c_j$.}
      \label{fig:non_kin_2}
    \end{figure}

    This proof follows the reasoning from Theorem \ref{thm:kin_2}, and is illustrated in Figure \ref{fig:non_kin_2}.
  \end{proof}

  \section{Experimental Results}

  \subsection{Real Robot Study} \label{section:real_robots}
  \subsection{Scalability Study} \label{section:scalability}

  In this experiment we investigate how the segregation behavior scales with the
  number of classes and the number of robots in the environment. We varied the
  number of classes from 1 to 25 and ran 100 trials with robots uniformly randomly
  distributed. All trials lasted 180 seconds.

  \myparagraph{Fixed number of robots per class}
  We studied the case in which every class has 10 robots. The results of this are
  plotted in Fig.~\ref{fig:num_classes_10}. We observe that the cost increases
  with the number of classes. As the number of classes increases,
  the density of the robots increases too. Hence, line-of-sight occlusions between robots are more likely,
  navigation is more difficult, and the clusters do not have a chance to coalesce.
  The important trend is that as the number of robots increases, the cost increase sublinearly.
  This suggests that our method scales well with the total number of robots.

  \myparagraph{Fixed total number of robots}
  We considered the scenario in which a fixed number of robots is split into an
  increasing number of classes. We set the number of robots to 100, so with 25
  classes 4 robots were still assigned to each class. As reported in
  Fig.~\ref{fig:num_classes_100}, the cost is very low for small numbers of classes
  and above 5 classes has no trend in cost. The initial low cost is due to the fact that
  with 100 robots to divided among few classes, line-of-sight to a kin is highly likely.
  Here the trend indicates that our methods scaled well with the number of classes.

  \begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{./images/num_classes_vs_cost_10_per_class.png}
    \caption{The average cost over 100 trials with $N$ classes, 10 robots per class.}
    \label{fig:num_classes_10}
  \end{figure}

  \begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{./images/num_classes_vs_cost_100_robots.png}
    \caption{The average cost over 100 trials with 100 robots divided into $N$ classes.}
    \label{fig:num_classes_100}
  \end{figure}

  \subsection{The Effect of Implementation Details of the Sensor} \label{section:sensor_impl}

  We observed that the implementation details of the sensor have a significant
  effect on the behavior of the controller.

  Initially, our method for determining sensor value from the simulated
  range-and-bearing system was to consider all the robots within some small angle
  in front of the robot and pick the closest one. This is very similar to what
  would be provided by a real-world camera that uses colored skirts on each robot
  and picks the largest blob as the robot to be detected. This sensor
  implementation works well and was used in all our experiments. However,
  we found later that, if the robots instead always prefer to react to kin over
  non-kin, clusters form more quickly and robustly. For example, if there are
  two robots within the field of view of a robot's sensor and the non-kin robot is
  closer, the robot would ignore it and execute the $S=1$ logic, which drives the
  robot towards the farther kin robot. Exploring exactly which of the various
  implementation details have what effect on cost is left for future work.

  \subsection{The Effect of the Beam Angle} \label{sec:aperture_angle}

  On a real robot, there must be some finite beam angle to the theoretically
  line-of-sight sensor. We ran 100 trials 180 seconds each in simulation with uniformly random
  initial distributions of 40 robots with various beam
  angles. Fig.~\ref{fig:beam_angle} shows the results, along with a diagram
  showing how we define beam angle. The best beam angle we tested was \ang{20},
  and angles smaller or larger became progressively worse. We found that at lower
  beam angles, it was possible for a robot to become stuck in groups of two or
  three, and the robots spent all their time looking at each other instead of
  peeking around them to find kin. At larger angles, we suspect the behavior fails
  because larger beam angles cause the rings to enlarge faster. When the rings become
  % FIXME %
  too large and the space between robots exceeds $2r+\epsilon$
  and are no longer a cluster as defined by \eqref{eq:connected}.

  \begin{figure}[t]
    \centering
    \begin{tikzpicture}[scale=0.75]
      \draw (0,0) circle (0.75);
      \draw (0,0) -- (5,0.7);
      \draw[dashed] (0,0) -- (5,0);
      \draw (0,0) -- (5,-0.7);
      \draw (4,0) arc [radius=4, start angle=0, end angle=8];
      \node at (4.25,0.25) {$\beta$};
    \end{tikzpicture}
    \includegraphics[width=1\linewidth]{./images/beam_angle.png}
    \caption{A \ang{15} degree half beam angle is best for segregation. Lower cost is better.}
    \label{fig:beam_angle}
  \end{figure}

  \subsection{The Effect of Beam Length} \label{section:beam_range}

  We consider what happens if the theoretically infinite-range sensor has finite
  range. We use \ang{15} half beam angle and the same experimental setup as with
  the beam angle experiments. We consider the maximum range of the sensor as the
  diagonal length of the square in which the robot are initially distributed. In
  all our experiments, this square was \SI{5}{\meter} on each side, so we consider
  a range of \SI{7.07}{\meter} to be effectively unlimited. We report the costs
  for beam ranges as a fraction of this maximum range. As shown in
  Fig.~\ref{fig:beam_range}, a beam range of 25\% of the theoretical maximum
  performs just as well as an infinite sensor. Below this, the performance
  degrades.

  \begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{./images/beam_length.png}
    \caption{Segregation is robust to small sensor beam ranges. The performance at 25\% of maximum range is indistinguishable from infinite range.}
    \label{fig:beam_range}
  \end{figure}

  \section{Conclusion}

  In this paper, we show how robots with only a ternary sensor and a controller
  which maps sensor readings to wheel speeds is capable of $N$-class segregation.
  This controller is invariant to the number of classes, and using the best found parameters
  we are able to construct theoretical guarantees on the emergent behavior in a simplified setting.
  We performed a grid search to learn about the full parameter space, and we
  investigated the effect of sensor implementation details and the number of
  robots and classes on performance. Our findings indicate that robust segregation
  with non-ideal sensors in reality is possible, although not guaranteed.

  \bibliographystyle{IEEEtran}
  \bibliography{RBE595.bib}

\end{document}
