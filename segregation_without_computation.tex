\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{cancel}
\usepackage{xfrac}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage[hidelinks]{hyperref}
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage{float}
\usepackage{tikz}
\usepackage{textcomp}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\hypersetup{colorlinks=false}

\begin{document}

\title{Segregation without Computation}

\author{
  \IEEEauthorblockN{Jordan Burklund}
  \IEEEauthorblockA{\textit{Worcester Polytechnic Institute} \\
  Worcester, MA \\
  jsburklund@wpi.edu}
  \and
  \IEEEauthorblockN{Michael Giancola}
  \IEEEauthorblockA{\textit{Worcester Polytechnic Institute} \\
  Worcester, MA \\
  mjgiancola@wpi.edu}
  \and
  \IEEEauthorblockN{Peter Mitrano}
  \IEEEauthorblockA{\textit{Worcester Polytechnic Institute} \\
  Worcester, MA \\
  pdmitrano@wpi.edu}
}

\maketitle

\begin{abstract}
  In this paper, we demonstrate that memoryless computeless robots are capable of $n$-class segregation. We evolve controllers for this behavior with a genetic algorithm and perform a grid search over all parameters to understand the full parameter space. We find that robust segregation is possible, although not guaranteed. Instead, we prove that aggregation of kin robots is guaranteed when some reasonable conditions are met.
\end{abstract}

\begin{IEEEkeywords}
  swarm robotics, robot aggregation, robot segregation
\end{IEEEkeywords}

\section{Introduction and Related Work}

  Many prior methods have demonstrated the ability to aggregate robots and objects in a distributed way, and some have shown the ability to perform such tasks with limited computation and sensing capabilities. Decentralized aggregation is frequently posed as a precursor to other swarm behaviors such as sorting, self-assembly, or coordinated motion \cite{gauci_evolving_2014} \cite{dorigo_evolving_2004}. Segregation is a natural extension of aggregation, and so we also desire algorithms for segregating robots into different clusters. In order to make this robust to individual failures and simple to implement, we would also like to achieve segregation with no communication between robots, no complex sensors, no leaders or beacons, and no environmental cues.

  In nature, we find many examples of aggregation and segregation. Segregation occurs in cells during embryogenesis, and segregation of objects can be found in ants who sort their brood \cite{santos_segregation_2014}. Furthermore, segregation is something humans do very quickly, and we can do so almost on reaction rather than carefully planned motion. These examples motivate the study of simple controllers for segregation.

  \subsection{Aggregation and Segregation}
    Robot aggregation is defined as having all robots in the swarm collect at a particular location in a distributed manner. Many swarm aggregation policies require robots to compute bearing and distance to other robots, to sense gradients in the environment, or to otherwise communicate information. However, implementing these communication systems is difficult in practice, so methods that do not require communication or complex sensing are desirable. In \cite{gauci_self-organized_2014}, the authors propose a new class of policies that require no computation.

    The work of \cite{gasparri_swarm_2012} does not restrict itself to a computeless or memoryless solution. Instead they develop an aggregation algorithm which enables robots to respond to guidance commands -- i.e., a human using hand gestures to indicate which direction the swarm should move. They show that swarms running their algorithm are able to follow guidance commands and stay aggregated without colliding. A simpler controller is used in \cite{bahgeci_evolving_2005}, where robots are equipped with IR distance sensors surrounding the robot, 4 microphones, and an omni-directional speaker. The policy is a linear combination of the IR sensor values and the intensity values of the microphones. The authors show that a genetic algorithm is able to find weights for the policy such that robots aggregate together. In \cite{ando_distributed_1999}, the authors present a robot aggregation model with very limited sensing and no memory, but allows the robots to perform computations to determine their next position. They prove that their algorithm is correct in theory, then run the algorithm in simulation.

    Finally, \cite{gauci_self-organized_2014} considers a binary sensor that maps directly to wheel velocities. The authors demonstrate extremely robust aggregation despite these limitations, and they also prove formally that aggregation is guaranteed and find theoretical bounds on aggregation time in simple situations. Similarly, the authors of \cite{gauci_clustering_2014} perform object aggregation with the same restrictions on sensing and control.

    Segregation of robots has received little attention in swarm robotics, however many researchers have focused on sorting of objects \cite{vardy_accelerated_2012} \cite{holland_collective_1998} \cite{tao_wang_collective_2004} \cite{holland_stigmergy_1999}. The study in \cite{santos_segregation_2014} shares our objective, however they assume that each class has the same number of robots and that each robot knows the position of all other robots. In contrast, we adhere to the memoryless computeless controller architecture with a simple ternary sensor. \cite{gros_segregation_2009} also explores segregation robots based on local interactions inspired by gravity, however they require a centralized broadcast or a consensus algorithm to agree on the source or direction of gravity.

  \subsection{Robots That Do Not Compute}

    The memoryless and computeless controllers originally proposed by \cite{gauci_self-organized_2014} has been extended to other tasks and been modified in many ways by other researchers.

    In \cite{kernbach_re-embodiment_2009}, the authors propose an aggregation policy roughly based on observations of bees clustering in an optimal temperature location. In their method, robots are only able to distinguish between collisions between another robot or a wall, can only sense the intensity of a light source when they have collided, and do not communicate information. Although the robots have limited sensing and communication capabilities, the authors show that robots can aggregate to an optimal light intensity location, and that the time to converge to the optimal location improves with increasing number of robots in the environment.

    Robots that do not compute and are memoryless have also been shown to aggregate around a specific object, circle in a ring around an object, and forage for obstacles \cite{johnson_evolving_2016}. In this work, the authors show one can construct simple cost functions to guide the evolution of controllers to do new, yet interesting tasks. However, they also report that in attempting to evolve a controller to rendezvous the robots around an object, they accidentally and consistently evolved a policy where the robots circled around the target object. This demonstrates that designing a cost function can be hard or unreliable. They achieved rendezvous by initializing the policy at generation zero to the policy found in \cite{gauci_self-organized_2014} for simple aggregation.

\section{Methodology}

  \subsection{Problem Formulation}

    We consider a collection of differential drive robots all executing the same controller in a homogeneous, two dimensional, obstacle free environment. The robots are equipped with a single forward facing line of sight sensor which can distinguish between the presence of a kin robot, a non-kin robot, and nothing. This sensor is assumed to have infinite length (we consider non-infinite length in Section \ref{section:beam_length}). We assign $I=0$ to the state when no robot is seen, $I=1$ to the detection of a kin robot, and $I=2$ to the detection of a non-kin robot. We allow for any number of classes, but the robots need not distinguish between different non-kin classes. They need only to detect if a robot is of the same class or not. The objective is to segregate robots into clusters, ideally such that all the robots of the same class are packed into one cluster with no non-kin robots.

    \begin{algorithm}[t!]
      \begin{algorithmic}
      \If {$I=0$} \State set wheel speeds to $v_{l_0}$, $v_{r_0}$
      \ElsIf {$I=1$} \State set wheel speeds to $v_{l_1}$, $v_{r_1}$
      \Else \State set wheel speeds to $v_{l_2}$, $v_{r_2}$
      \EndIf
      \end{algorithmic}
      \caption{Controller Design}
      \label{alg:controller}
    \end{algorithm}

    The controllers we use in our experiments are of the same form as in \cite{gauci_self-organized_2014}. They simply map each of the three sensor values to a set of wheel speeds. Pseudo-code for the controller is shown in Algorithm \ref{alg:controller}. This controller has six parameters:

    $$[\,v_{l_0}, v_{r_0}, v_{l_1}, v_{r_1}, v_{l_2}, v_{r_2}\,]$$

    Keeping with the form used in \cite{gauci_self-organized_2014}, we let these parameters range from -1 to 1. In simulation, we then scale this parameter to range from \SI{-20}{\centi\meter\per\second} to \SI{20}{\centi\meter\per\second}.

  \subsection{Simulation Environment}

    We use the ARGoS simulation environment to search for controller parameters and evaluate them, which has the advantage of allowing us to run trials much faster than on real robots \cite{pinciroli_argos:_2012}. In our simulations, we use a range and bearing sensor to implement the theoretical line of sight sensor. In our analysis, we describe the sensor as infinitely thin, but in practice it must have some small finite angle. We explore the performance effect of various beam angles in Section \ref{section:beam_angle}. We note here the detail that we consider robots to be connected in a cluster if the gap between them is \SI{5}{\centi\meter} or less. We now describe two approaches for finding these parameters, genetic algorithms and grid search.

  \subsection{Evolving Segregation}

    In order to quickly search for parameters to achieve segregation, we use a simple genetic algorithm to evolve controller parameters. The genetic algorithm we used is unmodified from the example MPGA code provided with the ARGoS simulator. The mutation strategy is simply to mutate each of these 6 parameters with some probability p ($0.05$ in our experiments). If a parameter is selected to be mutated, a uniformly random number from -1 to 1 is picked for the new value. Selection is performed by picking the two lowest cost individuals, and the next population is formed by crossing the parameters of these two individuals. The original two parents are always kept in the population so that the current lowest cost individual is never removed until a lower cost genome is discovered.

  \subsection{Cost Functions}

    As with any optimization algorithm, it is important to have a cost function that accurately assigns cost to behaviors. We explore two different cost functions, and we find that one of them did not behave as we expected (see Section \ref{section:evaluting_cost_functions}). The first is the cluster metric used by \cite{gauci_self-organized_2014}, which is the proportion of the number of robots in the largest cluster to the total number of robots. We will apply this for each class of robots and sum up the cluster-metric cost for each class to get the total cost. The negative sign is present because the cluster metric is 0 when no robots are connected and 1 when all robots in a class are connected, so the negative sign assigns more connections a lower cost. This was ultimately the cost function we used in grid search and all following experiments.

    \begin{align*}
      c_{\text{total}} &=  \frac{1}{n}\sum^n_{\text{classes}}\sum_{t=0}^{T-1} -t c_{\text{gauci}}^{(t)} \\
    \end{align*}

    We also tried a new cost function to address some concerns with the cluster metric. The cluster metric described above is problematic because it considers a straight line of robots to be one cluster. In some scenarios, we care about how tightly the swarm is packed in its clusters. This new metric uses the centroids of the robots in each class. We borrow the dispersion metric $u^{(t)}$ from \cite{gauci_self-organized_2014}, which essentially computes the sum of distances from each robot to the centroid, but in our case we apply this to each class of robots. Consider $u_i^{(t)}$ to be the dispersion of a particular class $i$ at time $t$. Given all the centroids $\bar{p}_i^{(t)}$ for each class $i$, we call the centroid of all of these centroids $\bar{P}^{(t)}$. We call this the centroid-of-centroids cost function, and it can be defined formally as follows:

    \begin{align*}
    c_{\text{intra}} &= \sum_{i=1}^n u_i^{(t)} \\
    c_{\text{inter}} &= -\frac{1} {4r^2}\sum_{i=1}^n{\lVert \bar{p}_i^{(t)} - \bar{P}_i^{(t)} \rVert}^2 \\
    c_{\text{total}} &=  \sum_{t=0}^{T-1} t (c_{\text{intra}} + c_{\text{inter}}) \\
    \end{align*}

  \subsection{Grid Search}

    In order to exhaustively search the space of possible controllers, we conduct a grid search of the 6-dimensional parameter space. Due to limited computational resources, we were only able to search with a resolution of 7 values per parameter, which means in total we evaluated $7^6=117649$ parameters. For each parameter, we ran 1 trial in 36 different initial configurations, with 180 seconds for each simulation. These configurations consisted of uniformly random placement, clusters, and lines of robots distributed throughout the environment. We chose to include some structure configurations (clusters and lines) because we discovered that they varied significantly in performance from uniform random configurations, and by explicitly evaluating on structure configurations we can speak more confidently about the ability of the controller to succeed in any configuration. Otherwise, we would need to have far more trials with uniformly random robot placement to make the same claims. We were able to parallelize across the 36 configurations and run at 75x real time, so it took approximately 4 days to evaluate all the controllers.

    Because the search space is 6 dimensional, we choose to visualize it by plotting every pair of parameters against each other. For example, we consider how the cost changes as $v_{l_0}$ and $v_{r_0}$ change. We note that these graphs, shown in Figure \ref{fig:grid_search}, show very similar patterns to the same plots presented by \cite{gauci_self-organized_2014}. As an example of reading these plots, we can tell from the plot of parameters 2 and 3 ($I=1$) that there were no good controllers where the left and right wheel speeds were equal and negative (dark squares in the upper left), and that the best controllers had slightly unequal values close to 1 (lightest squares in the bottom left). These plots also visualize how there are some sharp discontinuities where performance changes dramatically.

    \begin{figure}
      \centering
      \includegraphics[width=0.42\linewidth]{./images/0_1_grid_img.png}
      \includegraphics[width=0.42\linewidth]{./images/2_3_grid_img.png}
      \includegraphics[width=0.42\linewidth]{./images/4_5_grid_img.png}
      \includegraphics[width=0.42\linewidth]{./images/0_3_grid_img.png}
      \includegraphics[width=0.42\linewidth]{./images/0_5_grid_img.png}
      \includegraphics[width=0.42\linewidth]{./images/1_4_grid_img.png}
      \includegraphics[width=0.42\linewidth]{./images/1_2_grid_img.png}
      \includegraphics[width=0.42\linewidth]{./images/3_4_grid_img.png}
      \includegraphics[width=0.42\linewidth]{./images/2_5_grid_img.png}
      \includegraphics[width=0.42\linewidth]{./images/0_4_grid_img.png}
      \includegraphics[width=0.42\linewidth]{./images/1_5_grid_img.png}
      \includegraphics[width=0.42\linewidth]{./images/0_2_grid_img.png}
      \includegraphics[width=0.42\linewidth]{./images/1_3_grid_img.png}
      \includegraphics[width=0.42\linewidth]{./images/2_4_grid_img.png}
      \includegraphics[width=0.42\linewidth]{./images/3_5_grid_img.png}
      \caption{Each grid cell shows the cost of the best controller with the x-axis and y-axis parameters at that given cell value.}
      \label{fig:grid_search}
    \end{figure}

\section{The Emergent Behavior}

    After running 10 generations with 10 genomes per generation, the lowest cost controller we found was [0.5, -0.5, -0.2, 0.6, 0.6, 0.2]. Similarly, after running the grid search the best controller was [1, -$\sfrac{2}{3}$, $\sfrac{1}{3}$, 1, 1, 0]. For both of these controllers, the robots policy is to turn away from kin but turn the opposite way when they see nothing or non-kin. This cause the kin robots to zig-zag in a line towards their kin, and when multiple robots execute this behavior the kin robots form rings. An example of this can be seen below in Figure \ref{fig:rings}. Rarely, they also for these shrimp-like shapes which can also be seen in Figure \ref{fig:rings}.

    \begin{figure}
      \centering
      \includegraphics[width=0.7\linewidth]{./images/rings_example.png}
      \caption{the emergent behavior is rings of kin. These rings sometimes expand or rotate around the environment.}
      \label{fig:rings}
    \end{figure}

    The basic description ``they form rings'' does not do justice to the complexity of the emergent behavior. We strongly recommend you view the supplementary videos in Section \ref{section:videos} to appreciate it fully. For example, we notice that these rings expand over time, and that if they are disturbed by a non-kin robot trying to pass through, they break and reform in a fascinating snake-like manner.

\section{Controller Analysis}

  Now that we have found parameters that achieve what we consider segregation, we attempt to prove that aggregation between kin is guaranteed. In all of these proofs we will consider the controller found via grid search since it is the best controller.

  \subsection{Aggregation with Static Kin}

    We found from grid search that the parameters [1, -0.6667, 0.3333, 1.0, 1.0, 0.0] best achieve segregation as defined by our cluster metric cost function. We now analyze this controller formally. First, we prove that a single isolated robot executing this controller will aggregate to a static kin robot, or more importantly, a static cluster of kin robots. This proof is a variation of the Theorem 5.1 provided in \cite{gauci_self-organized_2014}. Consider a robot situated as shown in Figure \ref{fig:kin_aggregation}. The controller dictates that since a kin robot is seen, $I=1$, so $v_{l_1} = 0.3333$ and $v_{r_1} = 1$. This will cause the robot to turn counter-clockwise with some radius $R$. Without loss of generality, we define our coordinate system so that $c_i=[0,0]$ with the robot $i$ facing the $+x$ axis. For this analysis, we assume that the robot has a fixed, positive inter wheel distance $W$, and that the controller is executed in finite time steps. Our goal is to show that the distance between the position of the robot after executing our controller for one time step $p'_i$ and the kin robot $p_j$ is less than the distance between the initial position of the robot $p_i$ and the kin robot $p_j$. Formally, this is expressed by the following relationship:

    \begin{equation} \label{eq:agg}
      \lVert p_j - p'_i \rVert < \lVert p_j - p_i \rVert
    \end{equation}

    \begin{figure}
      \centering
      \begin{tikzpicture}
        \draw[white] (-2.25,3.5) rectangle(7,-4.75);

        \draw[->] (0,0) -- (6,0);
        \node at (6.2,.2) {x};
        \draw[->] (0,0) -- (0,3);
        \node at (-0.2,3.2) {y};

         % c_i
        \filldraw (0,0) circle (.05);
        \node at (.2,.2) {$c_i$};
        \draw[blue, dashed] (0,0) circle (2);

         % p_i
        \filldraw (0,-2) circle (.05);
        \node at (.2,-2.2) {$p_i$};
        \draw[blue] (0,-2) circle (0.85);
        \node at (-.3,-.8) {$R$};
        \draw[dashed] (0,0) -- (0,-2);

         % p'_i
        \filldraw (1.41,-1.41) circle (.05);
        \node at (1.85,-1.25) {$p'_i$};
        \draw[blue] (1.41,-1.41) circle (0.85);
        \draw[dashed] (0,0) -- (1.41,-1.41);
        \node at (.8,-.3) {$R$};

         % p_j
        \filldraw (5,-3.25) circle (.05);
        \node at (5.2,-3.5) {$p_j$};
        \draw[red] (5,-3.25) circle (1.25);
        \draw (5,-3.25) -- (5,-2);
        \node at (5.3,-2.625) {$r_j$};

        % delta
        \draw[blue] (0,-2) -- (5,-2);
        \draw[blue] (1.41,-1.41) -- (5.3,-2.03);
        \node at (2.5, -2.2) {$\delta$};

        % theta
        \draw (0,-.7) arc [radius=.7, start angle=-90, end angle=-45];
        \node at (.36,-.85) {$\theta$};
      \end{tikzpicture}
      \caption{The robot will always move closer to its Kin.}
      \label{fig:kin_aggregation}
    \end{figure}


    We emphasize that $r_j$ could be the radius of a single kin robot or the radius of a large cluster of kin robots. With this coordinate system defined and assumptions stated, we can define the coordinates of $p_i$, $p_j$, and $p'_i$.

    \begin{equation}
      \begin{split}
        p_i = \begin{bmatrix}0 \\ -R\end{bmatrix} \\
        p_j = \begin{bmatrix}\delta \\ -(R+r_j)\end{bmatrix} \\
        p'_i = \begin{bmatrix}R\sin(\theta) \\ -R\cos(\theta)\end{bmatrix}
      \end{split}
    \end{equation}

    We then substitute these variables into our inequality (Equation \ref{eq:agg}), and the result is shown in Equation \ref{eq:agg_result}. For the full derivation, see Appendix \ref{thm:1}. In short, the distance of the robot to its kin is guaranteed to decrease until a point where the sensor ray distance $\delta$ is not greater than some simple function of $\theta$ and $R$.

    \begin{equation} \label{eq:agg_result}
      \delta > (R + r_j)\tan\bigg(\frac{\theta}{2}\bigg)
    \end{equation}

    We can further calculate exactly how much closer the robot $i$ will be to robot $j$ after executing the $I=1$ state for one time step. As we show in Appendix \ref{thm:2}, the change in distance between the robots is exactly equal to Equation \ref{eq:dist_change}. We can use this equation to plot how the distance between the robots changes over time. We show an example of this for our simulated robot in Figure \ref{fig:dist_plot}.
    \begin{equation} \label{eq:dist_change}
      2R\big((r_j + R)(1 - \cos(\theta))-\delta\sin(\theta)\big)
    \end{equation}

    In both of these equations the dependent variables $\theta$ and $R$ are themselves a function of $\Delta t$, the inter wheel diameter $W$, and the wheels speeds of the controller $v_{l_1}$ and $v_{r_1}$, which are shown in Equation \ref{eq:theta_and_r}.

    \begin{align}
      \begin{split} \label{eq:theta_and_r}
        \theta &= \Delta t\omega = \Delta t \frac{v_{r_1} - v_{l_1}}{W} = \Delta t \frac{1 - (0.3333)}{W} = \frac{2\Delta t}{3W} \\
        R &= \frac{W}{2}\bigg(\frac{v_{r_1} + v_{l_1}}{v_{r_1} - v_{l_1}}\bigg) = \frac{W}{2}\bigg(\frac{1 + (0.3333)}{1 - (0.3333)}\bigg) = \frac{W}{4}
      \end{split}
    \end{align}

    Combining \ref{eq:theta_and_r} with \ref{eq:agg_result} gives us \ref{eq:agg_final_result}, which tells us the conditions under which aggregation is guaranteed. We emphasize that this does not mean aggregation to a kin is guaranteed for all values of $\Delta t$, $r_j$, and $W$. For example, if $\Delta t$ is increased to \SI{1}{\second} then aggregation is likely not guaranteed, simply because robot $i$ may have driven so far in its circle that it is further from $p_j$ than before.

    \begin{figure}
      \centering
      \includegraphics[width=1\linewidth]{./images/dist_plot.png}
      \caption{The distance between a robot and its kin after each step as it aggregates. We use $W=0.14$, $r_j=0.14$, $\Delta t=0.1$. In this example, aggregation took 60 iterations.}
      \label{fig:dist_plot}
    \end{figure}

    \begin{equation}
      \label{eq:agg_final_result}
      \delta > \bigg(\frac{W}{4} + r_j\bigg)\tan\bigg(\frac{\Delta t}{3W}\bigg)
    \end{equation}

    We can now consider an example with the FootBot robot. The inner wheel distance for the FootBot is $W=0.14$m, and in our simulations we use a time step of $\Delta t = 0.1s$. Therefore $\theta = 0.4761\;\text{rad}$ and $R=0.035$, and so aggregation is guaranteed when the following is true.

    \begin{equation} \label{eq:khephera_agg}
      \begin{split}
        \delta &> \bigg(0.035 + r_j\bigg)\tan\frac{0.4761}{2} \\
        \delta &> 0.2427 r_j + 0.0085
      \end{split}
    \end{equation}

     What we would like is for the right hand side of the equation to always be less than the distance at which the robots are considered aggregated. In other words, we want aggregation to be guaranteed until the sensor ray distance is small enough that aggregation has been achieved. We defined aggregation as when the distance between the robots $d \leq r_j+r_i$. Since the sensor ray length $\delta$ is always less than that distance, we can simply show that the right hand side of Equation \ref{eq:agg_final_result} is always less than $r_i+r_j$. Again we must consider an example since aggregation cannot be guaranteed in all scenarios, so going back to our example with the FootBot, we note that $0.2427r_j + 0.0085 < r_j+r_i$ is always true as long as $r_j>0$ and $r_i\geq0.0085$.

     We examined a wide range of possible values for our parameters $\Delta t$, $r_i$, $W$, and $r_j$, and we find that as long as $\Delta t$ is small (less than 0.25s), then aggregation is guaranteed for reasonable values of W (less than 0.5m).

\section{Experimental Results}

  \subsection{Evaluating the centroid-of-centroids cost function} \label{section:evaluting_cost_functions}

    When we implemented the centroid-of-centroids style cost function, we quickly found examples of configurations ranked in ways we did not like. One example is shown below in Figure \ref{fig:cost_function_fuckup}. The behavior that looks like aggregation was given lower cost of -8e9, versus the behavior that looks like segregation was given a cost of -5e9.

    \begin{figure}[H]
      \centering
      \includegraphics[width=0.49\linewidth]{./images/individual_0_gen_0.png}
      \includegraphics[width=0.49\linewidth]{./images/individual_0_gen_1_better.png}
      \caption{The left picture was given lower cost than the right, which is not desirable.}
      \label{fig:cost_function_fuckup}
    \end{figure}

  \subsection{Scalability Study} \label{section:scalability}

    In this experiment we investigate how segregation behavior scales with the number of classes and number of robots in the environment. We varied the number of classes from 1 to 25 and ran 100 trials of robots randomly distributed. Because our cost function is independent of the number of classes, we first considered having 10 robots for each class. However, this also means that in the trial with 25 classes there are 25 times the total number of robots than in the 1 class trial. This means that occlusion of robots is more likely so we are not surprised to find that cost increases with more classes. The results of this are plotted in Figure  \ref{fig:num_classes_10}. Another scenario is to consider a fixed number of robots and split them into more and more classes. We choose 100 robots because we are still able to get 4 robots per class at 25 classes. As you can see in Figure \ref{fig:num_classes_100}, the cost no longer increases as the number of classes increases. However, the cost for just a few classes is much higher. This is expected, because when there are many robots of a single class, our controller forms very large sparse rings where robots are too far to be considered clustered.

    Ultimately, we can say that our controller scales well to many classes with few robots, but not well to many robots of the same class.

    \begin{figure}[H]
      \centering
      \includegraphics[width=1\linewidth]{./images/num_classes_vs_cost_100_robots.png}
      \caption{The average cost with 100 robots divided into N classes. More classes are lower cost partially because kin robots stay close enough to be considered clusters.}
      \label{fig:num_classes_100}
    \end{figure}

    \begin{figure}[H]
      \centering
      \includegraphics[width=1\linewidth]{./images/num_classes_vs_cost_10_per_class.png}
      \caption{The average cost with N classes, 10 robots per class. More classes are higher cost because other robots obstruct your view making it difficult to find kin.}
      \label{fig:num_classes_10}
    \end{figure}

  \subsection{The Effect of Implementation Details of the sensor} \label{section:sensor_impl}

    So far we have been vague on how exactly we implement this theoretical line-of-sight sensor. We found in our experiments that the implementation details have a tremendous effect on the performance or behavior of the controller. This is unfortunate because one of the main motivations of the binary or ternary line of sight sensors is that they can be easily transferred between real and simulated implementations.

    Initially, our method for determining sensor state from our simulated range-and-bearing sensors was to consider all the robots within some small angle in front of the robot and pick the closest one. This is very similar to what you would presumably get from a real-world camera implementation that uses colored skirts on each robot and picks the largest blob as the robot to be detected. This sensor implementation works well and was used in all our genetic algorithm and grid search experiments. However, we found later that if instead the robots always prefer to react to kin over non-kin, you can form larger rings more quickly and robustly. For example, if there are two robots within the imagery beam of your sensor and the non-kin robot is closer, you will ignore it and execute the $I=1$ state which will drive you towards the farther away kin robot. Exploring exactly which of these implementation details have what effect on cost is left for future work.

  \subsection{The Effect of Beam Angle} \label{section:beam_angle}

    In practice, there must be some finite beam angle to the theoretically line of sight sensor. We ran 100 trials in simulation with uniformly random initial distributions of 40 robots with various half beam angles. Figure \ref{fig:beam_angle} shows the results, as well as a diagram showing how we define half beam angle. The best half beam angle we tested was \ang{15}, and angles smaller or larger got progressively worse. We found that at lower beam angles, it was possible for a robot to become stuck in groups of two or three where the robots spent all their time looking at each other and not peeking around them to find kin. At larger angles, we believe the behavior fails because larger beam angles cause the rings to enlarge faster, which in turn causes the rings to be so large that they are not considered a cluster anymore and so the cost rises.

    \begin{figure}[H]
      \centering
      \includegraphics[width=1\linewidth]{./images/beam_angle.png}
      \begin{tikzpicture}
        \draw (0,0) circle (0.75);
        \draw (0,0) -- (5,0.7);
        \draw[dashed] (0,0) -- (5,0);
        \draw (0,0) -- (5,-0.7);
        \draw (4,0) arc [radius=4, start angle=0, end angle=8];
        \node at (4.25,0.25) {$\beta$};
      \end{tikzpicture}
      \caption{A \ang{15} degree half beam angle is best for segregation. Lower cost is better.}
      \label{fig:beam_angle}
    \end{figure}

  \subsection{The Effect of Beam Length} \label{section:beam_length}

    We also consider what happens if our theoretically infinite sensor now has finite range. We use \ang{15} half beam angle and the same experimental setup as with the beam angle experiments. Like in \cite{gauci_self-organized_2014}, we consider the maximum range of the sensor as the diagonal length of the square in which the robot are initially distributed. In all our experiments, this box was \SI{5}{\meter\square}, so we consider a range of \SI{7.07}{\meter} to be effectively unlimited. We report the costs for beam lengths as a fraction of this maximum range. As you can see in Figure \ref{fig:beam_length}, in practice a beam length of only 35\% of the theoretical maximum performs just as well. Below this, the performance degrades. However, even a beam length of just 7\% of unlimited is more effective than zero length at segregation. In our experiment watching many simulations, beam length should also be scaled with the total number of robots as well as the initial distance between robots. When the beam length is short, there are many cases where two rings of kin robots form at different points in the environment, and in order for these two rings to join the robots must have sufficiently long beam length in order to detect each other.

    \begin{figure}
      \centering
      \includegraphics[width=1\linewidth]{./images/beam_length.png}
      \caption{Segregation is robust to very finite sensor beam lengths. The blue bar indicates the worst (highest) attainable cost in which all robots are isolated from any kin.}
      \label{fig:beam_length}
    \end{figure}

\section{Conclusion}

  In this paper, we demonstrate that memoryless, computeless robots are capable of $n$-class segregation. We use a simple controller design consisting of a 6-tuple. This controller is invariant to the number of classes, so any given controller can work for any number of classes. To quickly find a quality controller, we evolved one using a basic genetic algorithm, but we also performed a grid search to make claims about the full parameter space. We investigated the effect of sensor implementation details and the number of robots and classes on performance. We find that robust segregation is possible, although not guaranteed. Instead, we prove that aggregation of kin robots is guaranteed when reasonable conditions on controller frequency and inner wheel distance are met.

\bibliography{RBE595.bib}
\bibliographystyle{unsrt}

\onecolumn
\appendix
\section{Appendix}

  \subsection{Proof of Theorem 1} \label{thm:1}

    \begin{align*}
      \lVert p_j - p'_i \rVert &< \lVert p_j - p_i \rVert \\
      \sqrt{(p_{j_x} - p'_{i_x})^2 + (p_{j_y} - p'_{i_y})^2} &< \sqrt{(p_{j_x} - p_{i_x})^2 + (p_{j_y} - p_{i_y})^2} \\
      (p_{j_x} - p'_{i_x})^2 + (p_{j_y} - p'_{i_y})^2 &< (p_{j_x} - p_{i_x})^2 + (p_{j_y} - p_{i_y})^2 \\
      (\delta - R\sin(\theta))^2 + (-(R+r_j) + R\cos(\theta))^2 &< \delta^2 + (-(R+r_j) + R)^2 \\
      (\delta - R\sin(\theta))^2 + (-(R+r_j) + R\cos(\theta))^2 &< \delta^2 + r_j^2 \\
      \delta^2 - 2R\delta\sin(\theta) + R^2\sin(\theta)^2 + (r_j + R(1 - \cos(\theta))^2 &< \delta^2 + r_j^2 \\
      \delta^2 - 2R\delta\sin(\theta) + R^2\sin(\theta)^2 + r_j^2 + 2Rr_j(1 - \cos(\theta)) + R^2(1 - \cos(\theta))^2 &< \delta^2 + r_j^2 \\
      \delta^2 - 2R\delta\sin(\theta) + R^2\sin(\theta)^2 + r_j^2 + 2Rr_j - 2Rr_j\cos(\theta) + R^2(1 - \cos(\theta))^2 &< \delta^2 + r_j^2 \\
      \delta^2 - 2R\delta\sin(\theta) + R^2\sin(\theta)^2 + r_j^2 + 2Rr_j - 2Rr_j\cos(\theta) + R^2(1 - 2\cos(\theta) + \cos(\theta)^2) &< \delta^2 + r_j^2 \\
      \delta^2 - 2R\delta\sin(\theta) + R^2\sin(\theta)^2 + r_j^2 + 2Rr_j - 2Rr_j\cos(\theta) + R^2 - 2R^2\cos(\theta) + R^2\cos(\theta)^2 &< \delta^2 + r_j^2 \\
      \delta^2 - 2R\delta\sin(\theta) + R^2(\sin(\theta)^2 + cos(\theta)^2) + r_j^2 + 2Rr_j - 2Rr_j\cos(\theta) + R^2 - 2R^2\cos(\theta) &< \delta^2 + r_j^2 \\
      \cancel{\delta^2} - 2R\delta\sin(\theta) + 2R^2 + \cancel{r_j^2} + 2Rr_j - 2Rr_j\cos(\theta) - 2R^2\cos(\theta) &< \cancel{\delta^2} + \cancel{r_j^2} \\
      -2R\delta\sin(\theta) + 2R^2 + 2Rr_j - 2Rr_j\cos(\theta) - 2R^2\cos(\theta) &< 0 \\
      -\delta\sin(\theta) + R + r_j - r_j\cos(\theta) - R\cos(\theta) &< 0 \qquad \text{assuming $R>0$}\\
      R + r_j - r_j\cos(\theta) - R\cos(\theta) &< \delta\sin(\theta) \\
      r_j(1 - \cos(\theta)) + R(1 - \cos(\theta)) &< \delta\sin(\theta) \\
      (r_j+R)(1 - \cos(\theta)) &< \delta\sin(\theta) \\
      (R+r_j)\bigg(\frac{1 - \cos(\theta)}{\sin(\theta)}\bigg) &< \delta \\
      (R+r_j)\tan{\frac{\theta}{2}}  &< \delta \\
    \end{align*}

  \subsection{Proof of Theorem 2} \label{thm:2}

    \begin{align*}
      \Delta d &= d' - d \\
      &= \lVert p_j - p'_i \rVert - \lVert p_j - p_i \rVert \\
      &=\sqrt{(p_{j_x} - p'_{i_x})^2 + (p_{j_y} - p'_{i_y})^2} - \sqrt{(p_{j_x} - p_{i_x})^2 + (p_{j_y} - p_{i_y})^2} \\
      &=(p_{j_x} - p'_{i_x})^2 + (p_{j_y} - p'_{i_y})^2 - (p_{j_x} - p_{i_x})^2 + (p_{j_y} - p_{i_y})^2 \\
      &= (\delta - R\sin(\theta))^2 + (-(R+r_j) + R\cos(\theta))^2 - \delta^2 + (-(R+r_j) + R)^2 \\
      &= (\delta - R\sin(\theta))^2 + (-(R+r_j) + R\cos(\theta))^2 - \delta^2 + r_j^2 \\
      &= \delta^2 - 2R\delta\sin(\theta) + R^2\sin(\theta)^2 + (r_j + R(1 - \cos(\theta))^2 - \delta^2 + r_j^2 \\
      &= \delta^2 - 2R\delta\sin(\theta) + R^2\sin(\theta)^2 + r_j^2 + 2Rr_j(1 - \cos(\theta)) + R^2(1 - \cos(\theta))^2 - \delta^2 + r_j^2 \\
      &= \delta^2 - 2R\delta\sin(\theta) + R^2\sin(\theta)^2 + r_j^2 + 2Rr_j - 2Rr_j\cos(\theta) + R^2(1 - \cos(\theta))^2 - \delta^2 + r_j^2 \\
      &= \delta^2 - 2R\delta\sin(\theta) + R^2\sin(\theta)^2 + r_j^2 + 2Rr_j - 2Rr_j\cos(\theta) + R^2(1 - 2\cos(\theta) + \cos(\theta)^2) - \delta^2 + r_j^2 \\
      &= \delta^2 - 2R\delta\sin(\theta) + R^2\sin(\theta)^2 + r_j^2 + 2Rr_j - 2Rr_j\cos(\theta) + R^2 - 2R^2\cos(\theta) + R^2\cos(\theta)^2 - \delta^2 + r_j^2 \\
      &= \delta^2 - 2R\delta\sin(\theta) + R^2(\sin(\theta)^2 + cos(\theta)^2) + r_j^2 + 2Rr_j - 2Rr_j\cos(\theta) + R^2 - 2R^2\cos(\theta) - \delta^2 + r_j^2 \\
      &= \cancel{\delta^2} - 2R\delta\sin(\theta) + 2R^2 + \cancel{r_j^2} + 2Rr_j - 2Rr_j\cos(\theta) - 2R^2\cos(\theta) - \cancel{\delta^2} + \cancel{r_j^2} \\
      &= -2R\delta\sin(\theta) + 2R^2 + 2Rr_j - 2Rr_j\cos(\theta) - 2R^2\cos(\theta) \\
      &= 2R\big(-\delta\sin(\theta) + R + r_j - r_j\cos(\theta) - R\cos(\theta)\big) \\
      &= 2R\big((r_j + R)(1 - \cos(\theta))-\delta\sin(\theta)\big) \\
    \end{align*}

  \subsection{Supplementary Videos} \label{section:videos}

    This YouTube playlist contains videos of the controller found with grid search:

    \href{https://www.youtube.com/playlist?list=PL9HqYJ1IkIKVX9EsT5BY9LnBsBPTjc5bB}{https://goo.gl/z8UAuB}


\end{document}
